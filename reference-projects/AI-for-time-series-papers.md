### AAAI 2024



#### Time Series Forecasting



- U-Mixer: An Unet-Mixer Architecture with Stationarity Correction for Time Series Forecasting [[paper\]](https://arxiv.org/abs/2401.02236)
- HDMixer: Hierarchical Dependency with Extendable Patch for Multivariate Time Series Forecasting [[paper\]](https://github.com/qingsongedu/awesome-AI-for-time-series-papers/blob/main)
- Considering Nonstationary within Multivariate Time Series with Variational Hierarchical Transformer for Forecasting [[paper\]](https://github.com/qingsongedu/awesome-AI-for-time-series-papers/blob/main)
- Learning from Polar Representation: An Extreme-Adaptive Model for Long-Term Time Series Forecasting [[paper\]](https://arxiv.org/abs/2312.08763)
- MSGNet: Learning Multi-Scale Inter-Series Correlations for Multivariate Time Series Forecasting [[paper\]](https://arxiv.org/abs/2401.00423)
- Latent Diffusion Transformer for Probabilistic Time Series Forecasting [[paper\]](https://github.com/qingsongedu/awesome-AI-for-time-series-papers/blob/main)
- Spatio-Temporal Pivotal Graph Neural Networks for Traffic Flow Forecasting [[paper\]](https://github.com/qingsongedu/awesome-AI-for-time-series-papers/blob/main)

**Compared models of this leaderboard.** â˜‘ means that their codes have already been included in this repo.

-  **TimeXer** - TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables [[NeurIPS 2024\]](https://arxiv.org/abs/2402.19072) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/TimeXer.py)
-  **TimeMixer** - TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting [[ICLR 2024\]](https://openreview.net/pdf?id=7oLshfEIC2) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/TimeMixer.py).
-  **TSMixer** - TSMixer: An All-MLP Architecture for Time Series Forecasting [[arXiv 2023\]](https://arxiv.org/pdf/2303.06053.pdf) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/TSMixer.py)
-  **iTransformer** - iTransformer: Inverted Transformers Are Effective for Time Series Forecasting [[ICLR 2024\]](https://arxiv.org/abs/2310.06625) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/iTransformer.py).
-  **PatchTST** - A Time Series is Worth 64 Words: Long-term Forecasting with Transformers [[ICLR 2023\]](https://openreview.net/pdf?id=Jbdc0vTOcol) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/PatchTST.py).
-  **TimesNet** - TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis [[ICLR 2023\]](https://openreview.net/pdf?id=ju_Uqw384Oq) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/TimesNet.py).
-  **DLinear** - Are Transformers Effective for Time Series Forecasting? [[AAAI 2023\]](https://arxiv.org/pdf/2205.13504.pdf) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/DLinear.py).
-  **LightTS** - Less Is More: Fast Multivariate Time Series Forecasting with Light Sampling-oriented MLP Structures [[arXiv 2022\]](https://arxiv.org/abs/2207.01186) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/LightTS.py).
-  **ETSformer** - ETSformer: Exponential Smoothing Transformers for Time-series Forecasting [[arXiv 2022\]](https://arxiv.org/abs/2202.01381) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/ETSformer.py).
-  **Non-stationary Transformer** - Non-stationary Transformers: Exploring the Stationarity in Time Series Forecasting [[NeurIPS 2022\]](https://openreview.net/pdf?id=ucNDIDRNjjv) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/Nonstationary_Transformer.py).
-  **FEDformer** - FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting [[ICML 2022\]](https://proceedings.mlr.press/v162/zhou22g.html) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/FEDformer.py).
-  **Pyraformer** - Pyraformer: Low-complexity Pyramidal Attention for Long-range Time Series Modeling and Forecasting [[ICLR 2022\]](https://openreview.net/pdf?id=0EXmFzUn5I) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/Pyraformer.py).
-  **Autoformer** - Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting [[NeurIPS 2021\]](https://openreview.net/pdf?id=I55UqU-M11y) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/Autoformer.py).
-  **Informer** - Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting [[AAAI 2021\]](https://ojs.aaai.org/index.php/AAAI/article/view/17325/17132) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/Informer.py).
-  **Reformer** - Reformer: The Efficient Transformer [[ICLR 2020\]](https://openreview.net/forum?id=rkgNKkHtvB) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/Reformer.py).
-  **Transformer** - Attention is All You Need [[NeurIPS 2017\]](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/Transformer.py).

See our latest paper [[TimesNet\]](https://arxiv.org/abs/2210.02186) for the comprehensive benchmark. We will release a real-time updated online version soon.

**Newly added baselines.** We will add them to the leaderboard after a comprehensive evaluation.

-  **MultiPatchFormer** - A multiscale model for multivariate time series forecasting [[Scientific Reports 2025\]](https://www.nature.com/articles/s41598-024-82417-4) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/MultiPatchFormer.py)
-  **WPMixer** - WPMixer: Efficient Multi-Resolution Mixing for Long-Term Time Series Forecasting [[AAAI 2025\]](https://arxiv.org/abs/2412.17176) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/WPMixer.py)
-  **PAttn** - Are Language Models Actually Useful for Time Series Forecasting? [[NeurIPS 2024\]](https://arxiv.org/pdf/2406.16964) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/PAttn.py)
-  **Mamba** - Mamba: Linear-Time Sequence Modeling with Selective State Spaces [[arXiv 2023\]](https://arxiv.org/abs/2312.00752) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/Mamba.py)
-  **SegRNN** - SegRNN: Segment Recurrent Neural Network for Long-Term Time Series Forecasting [[arXiv 2023\]](https://arxiv.org/abs/2308.11200.pdf) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/SegRNN.py).
-  **Koopa** - Koopa: Learning Non-stationary Time Series Dynamics with Koopman Predictors [[NeurIPS 2023\]](https://arxiv.org/pdf/2305.18803.pdf) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/Koopa.py).
-  **FreTS** - Frequency-domain MLPs are More Effective Learners in Time Series Forecasting [[NeurIPS 2023\]](https://arxiv.org/pdf/2311.06184.pdf) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/FreTS.py).
-  **MICN** - MICN: Multi-scale Local and Global Context Modeling for Long-term Series Forecasting [[ICLR 2023\]](https://openreview.net/pdf?id=zt53IDUR1U)[[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/MICN.py).
-  **Crossformer** - Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting [[ICLR 2023\]](https://openreview.net/pdf?id=vSVLM2j9eie)[[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/Crossformer.py).
-  **TiDE** - Long-term Forecasting with TiDE: Time-series Dense Encoder [[arXiv 2023\]](https://arxiv.org/pdf/2304.08424.pdf) [[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/TiDE.py).
-  **SCINet** - SCINet: Time Series Modeling and Forecasting with Sample Convolution and Interaction [[NeurIPS 2022\]](https://openreview.net/pdf?id=AyajSjTAzmg)[[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/SCINet.py).
-  **FiLM** - FiLM: Frequency improved Legendre Memory Model for Long-term Time Series Forecasting [[NeurIPS 2022\]](https://openreview.net/forum?id=zTQdHSQUQWc)[[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/FiLM.py).
-  **TFT** - Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting [[arXiv 2019\]](https://arxiv.org/abs/1912.09363)[[Code\]](https://github.com/thuml/Time-Series-Library/blob/main/models/TemporalFusionTransformer.py).

